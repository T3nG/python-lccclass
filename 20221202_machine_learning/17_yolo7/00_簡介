yolo v7
1. AI演算的了解有助於設計模型: 台灣目前無此團隊, 僅有學術研究而已
2. AI建模: 使用別人設計好的模型, 傳入資料, 加以訓練, 稱為建模: 台灣業界的模式

Yolo: You only look once 與 Google Object Detection (GOD) 一樣, 但 GOD判定的速度較慢,
且無法相容於高版本的 CUDA(GOD僅適用於 CUDA 11.2),
同屬於 SSD(Single Shot MultiBox Detector) 單鏡頭多盒檢視器
Yolo 由 Joseph Redmon 開發, 但他發現這是很恐怖的東西, 所以退出不再研究,
後來由台灣教授與俄羅斯學者共同開發 Yolo v4
Yolo v6, v7由大陸主導開發

Yolo v4及之前, 使用 darknet框架, v5開始全面改用 pytorch框架
darknet還須安裝 Visual Studio 2019才可進行編譯, VS2019還是建議安裝
v5 pytorch開始, 只要在python執行即可

安裝套件
pip install tqdm requests matplotlib scipy pandas seaborn ipython psutil thop tensorboard
pip install pyyaml pyqt5 opencv-python
pip install protobuf==3.20.1
pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html
若 pip 裝不起來, 到老師的網站下載 http://mahaljsp.asuscomm.com/files/torch/torch.zip
下載下來的三個檔案放到專案下, 透過 pip install 安裝, 安裝順序 torch, vision, audio


底下的資料非常龐大, 有25G
train: http://images.cocodataset.org/zips/train2017.zip
test: http://images.cocodataset.org/zips/test2017.zip
validate: http://images.cocodataset.org/zips/val2017.zip
labels: https://github.com/WongKinYiu/yolov7/releases/download/v0.1/coco2017labels-segments.zip

下載主程式
https://github.com/wongkinyiu/yolov7
    點選 code/download zip
將 yolov7-main 裡面所有的檔及目錄, 移到專案下

於同網頁, Testing項目下
下載權重: yolov7.pt
    置於專案裡面

偵測圖片
0. 依提示安裝 numpy>=1.18.5,<1.24.0
1. 準備幾張圖片
2. 進入命令提示字元視窗
    進入專案下 yolo7-main
    cd E:\GitHub\python-lccclass\20221202_machine_learning\17_yolo7
    venv\Scripts\python detect.py --weights yolov7.pt --conf 0.25 --img-size 1920 --view-img --source E:\project\data\img\yolo7testimg\f.jpg

--conf 0.25 信心度

3. 結果會儲存在專案下 yolo7-main\runs\detect\exp(exp2, exp3)
4. 不只可偵測圖片, 也可偵測影片(mp4)
    --source 指定影片位置
5. 更改 detect, 使 python可以傳入參數, 也保留原本由命令提示字元傳入參數的功能
   def detect(save_img=False, myopt=None):
       global opt
       if myopt is not None : opt=myopt
       ...
       return im0
6. 更改字體大小 utils\plots.py
    依實際需求進行更改, 跟圖片大小有關
    def plot_one_box
        ...fontScale = t1 / 3   =>  t1 / 0.5
        ...cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 0.5, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)